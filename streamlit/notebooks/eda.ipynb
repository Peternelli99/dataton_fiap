{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Metodologia Aplicada\n",
    "\n",
    "Etapa A — Pré‑processamento Completo:\n",
    "\n",
    "- Carregamento e flatten de estruturas JSON hierárquicas em DataFrames relacionais\n",
    "- Junção das três entidades preservando relacionamento vaga → prospects → candidatos\n",
    "- Limpeza de duplicatas, normalização de strings e harmonização de valores categóricos\n",
    "- Tratamento de valores ausentes com estratégias domain‑specific (\"Desconhecido\" para categóricas)\n",
    "- One‑hot encoding controlado apenas em variáveis de baixa cardinalidade para evitar explosão dimensional\n",
    "- Normalização Z‑score em features numéricas para compatibilidade com algoritmos de ML\n",
    "\n",
    "Etapa B — Engenharia de Features Específicas:\n",
    "\n",
    "- Match Técnico: tech_overlap_count calcula interseção de competências entre vaga e candidato usando NLP básico\n",
    "- Sinalização SAP: sap_pair identifica sincronia entre demanda SAP da vaga e conhecimento do candidato\n",
    "- Compatibilidade de Idiomas: ingles_ok/espanhol_ok avaliam se candidato atende requisitos mínimos de idioma\n",
    "- Análise de Senioridade: senioridade_gap/senioridade_ok medem alinhamento de nível profissional\n",
    "- Dinâmica do Funil: days_update/situacao_ord capturam velocidade e posição no processo seletivo\n",
    "- Features de Interação: ok_eng_sen/len_cv_bin combinam sinais para capturar efeitos não‑lineares\n",
    "\n",
    "Resultado Esperado Quantificado\n",
    "Dataset Final:\n",
    "\n",
    "- Tamanho: 53.759 registros (combinações únicas vaga‑candidato) × 21 colunas otimizadas\n",
    "- Estrutura: 2 chaves relacionais + 19 features preditivas especializadas em recrutamento\n",
    "- Qualidade: Dados limpos, tipos otimizados (int8, float32), sem valores ausentes tratados\n",
    "- Formato: CSV UTF‑8\n",
    "\n",
    "Features de Alta Qualidade:\n",
    "\n",
    "- tech_overlap_count: métrica quantitativa de compatibilidade técnica (0‑20)\n",
    "- sap_pair: flag binária para match SAP especializado (0/1)\n",
    "- ingles_ok/espanhol_ok: flags de atendimento a requisitos de idioma (0/1)\n",
    "- senioridade_gap: diferença ordinal entre senioridade candidato‑vaga (‑3 a +3)\n",
    "- situacao_ord: posição ordinal no funil de recrutamento (0=Cadastrado, 5=Contratado)\n",
    "- days_update: velocidade temporal de progressão no funil (dias)\n",
    "- len_cv_pt_z: tamanho normalizado do CV como proxy de experiência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação da correção:\n",
      "Total de registros: 53759\n",
      "Distribuição situacao_ord:\n",
      "situacao_ord\n",
      "2    43496\n",
      "3     1048\n",
      "4     6231\n",
      "5     2984\n",
      "Name: count, dtype: Int64\n",
      "Candidatos contratados (situacao_ord=5): 2984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(WindowsPath('c:/Users/Dell/datathon/streamlit/notebooks/../data/df.csv'),\n",
       " (53759, 21))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOCO A — CONFIGURAÇÃO INICIAL E CARREGAMENTO DOS DADOS\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "BASE = Path.cwd()\n",
    "DATA_DIR = BASE / \"../data/\" \n",
    "\n",
    "PATH_VAGAS = DATA_DIR / \"vagas.json\"\n",
    "PATH_PROSPECTS = DATA_DIR / \"prospects.json\"\n",
    "PATH_APPLICANTS = DATA_DIR / \"applicants.json\"\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "raw_vagas = load_json(PATH_VAGAS)\n",
    "raw_prospects = load_json(PATH_PROSPECTS)\n",
    "raw_applicants = load_json(PATH_APPLICANTS)\n",
    "\n",
    "# BLOCO B — TRANSFORMAÇÃO DE DADOS HIERÁRQUICOS EM ESTRUTURA TABULAR\n",
    "# Vagas (Jobs)\n",
    "df_vagas = pd.json_normalize(list(raw_vagas.values()), sep='.')\n",
    "df_vagas[\"vaga_id\"] = list(map(str, raw_vagas.keys()))\n",
    "cols_vagas = [\n",
    "    \"vaga_id\",\n",
    "    \"informacoes_basicas.titulo_vaga\",\n",
    "    \"informacoes_basicas.vaga_sap\",\n",
    "    \"informacoes_basicas.cliente\",\n",
    "    \"perfil_vaga.nivel_profissional\",\n",
    "    \"perfil_vaga.nivel_ingles\",\n",
    "    \"perfil_vaga.nivel_espanhol\",\n",
    "    \"perfil_vaga.cidade\",\n",
    "    \"perfil_vaga.estado\",\n",
    "    \"perfil_vaga.pais\",\n",
    "    \"perfil_vaga.principais_atividades\",\n",
    "    \"perfil_vaga.competencia_tecnicas_e_comportamentais\",\n",
    "]\n",
    "df_vagas = df_vagas[[c for c in cols_vagas if c in df_vagas.columns]]\n",
    "\n",
    "# Prospects (por vaga)\n",
    "rows = []\n",
    "for vaga_id, payload in raw_prospects.items():\n",
    "    for p in payload.get(\"prospects\", []):\n",
    "        r = p.copy()\n",
    "        r[\"vaga_id\"] = str(vaga_id)\n",
    "        rows.append(r)\n",
    "df_prospects = pd.DataFrame(rows).rename(columns={\"codigo\":\"codigo_candidato\",\"situacao_candidado\":\"situacao_candidato\"})\n",
    "\n",
    "# Applicants (candidatos)\n",
    "df_app = pd.json_normalize(list(raw_applicants.values()), sep='.')\n",
    "df_app[\"codigo_candidato\"] = list(map(str, raw_applicants.keys()))\n",
    "if \"infos_basicas.codigo_profissional\" in df_app.columns:\n",
    "    df_app[\"codigo_candidato\"] = df_app[\"infos_basicas.codigo_profissional\"].fillna(df_app[\"codigo_candidato\"]).astype(str)\n",
    "\n",
    "cols_app = [\n",
    "    \"codigo_candidato\",\n",
    "    \"infos_basicas.nome\",\n",
    "    \"informacoes_profissionais.titulo_profissional\",\n",
    "    \"informacoes_profissionais.area_atuacao\",\n",
    "    \"formacao_e_idiomas.nivel_academico\",\n",
    "    \"formacao_e_idiomas.nivel_ingles\",\n",
    "    \"formacao_e_idiomas.nivel_espanhol\",\n",
    "    \"informacoes_profissionais.conhecimentos_tecnicos\",\n",
    "    \"cv_pt\",\n",
    "]\n",
    "df_app = df_app[[c for c in cols_app if c in df_app.columns]]\n",
    "\n",
    "# Join final\n",
    "df = df_prospects.merge(df_vagas, on=\"vaga_id\", how=\"left\").merge(df_app, on=\"codigo_candidato\", how=\"left\")\n",
    "\n",
    "# BLOCO C — PRÉ-PROCESSAMENTO CORRIGIDO\n",
    "df = df.drop_duplicates(subset=[\"vaga_id\",\"codigo_candidato\"], keep=\"first\")\n",
    "for c in df.select_dtypes(include=\"object\").columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Normalização de valores conhecidos\n",
    "if \"informacoes_basicas.vaga_sap\" in df.columns:\n",
    "    df[\"informacoes_basicas.vaga_sap\"] = df[\"informacoes_basicas.vaga_sap\"].str.lower().map(\n",
    "        {\"sim\":\"Sim\",\"yes\":\"Sim\",\"true\":\"Sim\",\"não\":\"Não\",\"nao\":\"Não\",\"no\":\"Não\"}\n",
    "    ).fillna(\"Não\")\n",
    "\n",
    "# Numérica simples\n",
    "df[\"len_cv_pt\"] = df.get(\"cv_pt\",\"\").astype(str).str.len()\n",
    "df[\"len_cv_pt\"] = pd.to_numeric(df[\"len_cv_pt\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# One-hot apenas em baixa cardinalidade\n",
    "low_card = [\n",
    "    \"situacao_candidato\",\n",
    "    \"informacoes_basicas.vaga_sap\",\n",
    "    \"perfil_vaga.nivel_profissional\",\n",
    "    \"perfil_vaga.nivel_ingles\",\n",
    "    \"perfil_vaga.nivel_espanhol\",\n",
    "]\n",
    "for c in low_card:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace({\"\": np.nan}).fillna(\"Desconhecido\")\n",
    "\n",
    "df_enc = pd.get_dummies(df, columns=[c for c in low_card if c in df.columns], drop_first=True, dtype=np.int8)\n",
    "\n",
    "# Normalização de numéricas\n",
    "scaler = StandardScaler()\n",
    "df_enc[\"len_cv_pt_z\"] = scaler.fit_transform(df_enc[[\"len_cv_pt\"]]).astype(np.float32)\n",
    "df_enc = df_enc.drop(columns=[\"len_cv_pt\"], errors=\"ignore\")\n",
    "\n",
    "# BLOCO D — FEATURES ENGINEERING COM MAPEAMENTO CORRIGIDO\n",
    "def get_series(df_, col, default=\"\"):\n",
    "    return df_[col] if col in df_.columns else pd.Series([default] * len(df_), index=df_.index)\n",
    "\n",
    "def norm_txt(s):\n",
    "    s = \"\" if pd.isna(s) else str(s).lower()\n",
    "    s = re.sub(r\"[^a-z0-9áâãàéêíóôõúç\\+\\#\\.\\- ]\",\" \",s)\n",
    "    return re.sub(r\"\\s+\",\" \",s).strip()\n",
    "\n",
    "TECH_TERMS = [\"sap\",\"abap\",\"hana\",\"sql\",\"python\",\"java\",\".net\",\"c#\",\"node\",\"aws\",\"azure\",\"gcp\",\"linux\",\"docker\",\"kubernetes\",\"oracle\",\"mysql\",\"postgres\",\"power bi\",\"tableau\"]\n",
    "def extract_terms(text):\n",
    "    t = norm_txt(text)\n",
    "    return {tkn for tkn in TECH_TERMS if tkn in t}\n",
    "\n",
    "# Overlap técnico e SAP\n",
    "vaga_txt = (get_series(df, \"perfil_vaga.principais_atividades\").astype(str) + \" \" +\n",
    "            get_series(df, \"perfil_vaga.competencia_tecnicas_e_comportamentais\").astype(str))\n",
    "cand_txt = get_series(df, \"informacoes_profissionais.conhecimentos_tecnicos\").astype(str) + \" \" + \\\n",
    "           get_series(df, \"cv_pt\").astype(str)\n",
    "\n",
    "vt = vaga_txt.map(extract_terms)\n",
    "ct = cand_txt.map(extract_terms)\n",
    "df_enc[\"tech_overlap_count\"] = [len(a.intersection(b)) for a,b in zip(vt,ct)]\n",
    "\n",
    "df_enc[\"is_sap_vaga\"] = get_series(df, \"informacoes_basicas.vaga_sap\",\"Não\").eq(\"Sim\").astype(np.int8)\n",
    "df_enc[\"cand_has_sap\"] = cand_txt.str.contains(r\"\\bsap\\b\", regex=True, na=False).astype(np.int8)\n",
    "df_enc[\"sap_pair\"] = (df_enc[\"is_sap_vaga\"] & df_enc[\"cand_has_sap\"]).astype(np.int8)\n",
    "\n",
    "# Idiomas\n",
    "LANG_MAP = {\"basico\":1,\"básico\":1,\"a1\":1,\"a2\":2,\"intermediario\":3,\"intermediário\":3,\"b1\":3,\"b2\":4,\"avancado\":5,\"avançado\":5,\"fluente\":6,\"c1\":6,\"c2\":7}\n",
    "def lang_rank(s):\n",
    "    s = norm_txt(s)\n",
    "    m = re.search(r\"\\b([abc][12])\\b\", s)\n",
    "    if m:\n",
    "        return LANG_MAP.get(m.group(1),0)\n",
    "    for k,v in LANG_MAP.items():\n",
    "        if k in s:\n",
    "            return v\n",
    "    return 0\n",
    "\n",
    "df_enc[\"vaga_ing_rank\"] = get_series(df, \"perfil_vaga.nivel_ingles\").astype(str).apply(lang_rank).astype(\"Int8\")\n",
    "df_enc[\"vaga_esp_rank\"] = get_series(df, \"perfil_vaga.nivel_espanhol\").astype(str).apply(lang_rank).astype(\"Int8\")\n",
    "df_enc[\"cand_ing_rank\"] = get_series(df, \"formacao_e_idiomas.nivel_ingles\").astype(str).apply(lang_rank).astype(\"Int8\")\n",
    "df_enc[\"cand_esp_rank\"] = get_series(df, \"formacao_e_idiomas.nivel_espanhol\").astype(str).apply(lang_rank).astype(\"Int8\")\n",
    "df_enc[\"ingles_ok\"] = (df_enc[\"cand_ing_rank\"] >= df_enc[\"vaga_ing_rank\"]).astype(np.int8)\n",
    "df_enc[\"espanhol_ok\"] = (df_enc[\"cand_esp_rank\"] >= df_enc[\"vaga_esp_rank\"]).astype(np.int8)\n",
    "\n",
    "# Senioridade\n",
    "def sen_vaga(s):\n",
    "    s = norm_txt(s)\n",
    "    return 3 if \"sen\" in s else 2 if \"plen\" in s else 1 if \"jun\" in s else 0\n",
    "\n",
    "def sen_cand_from_title(s):\n",
    "    s = norm_txt(s)\n",
    "    return 3 if \"sen\" in s else 2 if \"plen\" in s else 1 if \"jun\" in s else 0\n",
    "\n",
    "df_enc[\"vaga_sen_rank\"] = get_series(df, \"perfil_vaga.nivel_profissional\").astype(str).apply(sen_vaga).astype(\"Int8\")\n",
    "df_enc[\"cand_sen_rank\"] = get_series(df, \"informacoes_profissionais.titulo_profissional\").astype(str).apply(sen_cand_from_title).astype(\"Int8\")\n",
    "df_enc[\"senioridade_gap\"] = (df_enc[\"cand_sen_rank\"] - df_enc[\"vaga_sen_rank\"]).astype(\"Int8\")\n",
    "df_enc[\"senioridade_ok\"] = (df_enc[\"cand_sen_rank\"] >= df_enc[\"vaga_sen_rank\"]).astype(np.int8)\n",
    "\n",
    "# Funil e tempo com MAPEAMENTO CORRIGIDO\n",
    "def to_date(s): \n",
    "    return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "df_enc[\"dt_cand\"] = get_series(df, \"data_candidatura\").apply(to_date)\n",
    "df_enc[\"dt_ult\"] = get_series(df, \"ultima_atualizacao\").apply(to_date)\n",
    "df_enc[\"days_update\"] = (df_enc[\"dt_ult\"] - df_enc[\"dt_cand\"]).dt.days.fillna(0).astype(np.int16)\n",
    "\n",
    "# CORREÇÃO CRÍTICA: Mapeamento robusto de situações de contratação\n",
    "def map_situacao_ordinal(situacao_str):\n",
    "    \"\"\"Mapeia situações do candidato para valores ordinais, incluindo variações de 'Contratado'\"\"\"\n",
    "    if pd.isna(situacao_str):\n",
    "        return 2  # Default para \"Encaminhado ao Requisitante\"\n",
    "    \n",
    "    situacao_clean = str(situacao_str).lower().strip()\n",
    "    \n",
    "    # Mapeamento robusto que captura todas as variações\n",
    "    if \"contratado\" in situacao_clean:  # Captura \"Contratado\" E \"Contratado pela Decision\"\n",
    "        return 5\n",
    "    elif \"aprovado\" in situacao_clean:\n",
    "        return 4\n",
    "    elif \"entrevista\" in situacao_clean:\n",
    "        return 3\n",
    "    elif \"encaminhado\" in situacao_clean:\n",
    "        return 2\n",
    "    elif \"contato\" in situacao_clean:\n",
    "        return 1\n",
    "    elif \"cadastrado\" in situacao_clean:\n",
    "        return 0\n",
    "    elif \"reprovado\" in situacao_clean:\n",
    "        return 6\n",
    "    else:\n",
    "        return 2  # Default para situações não mapeadas\n",
    "\n",
    "df_enc[\"situacao_ord\"] = get_series(df, \"situacao_candidato\").apply(map_situacao_ordinal).astype(\"Int8\")\n",
    "\n",
    "# Binning e interação principal\n",
    "len_cv_pt_raw = get_series(df, \"cv_pt\").astype(str).str.len()\n",
    "df_enc[\"len_cv_bin\"] = pd.qcut(len_cv_pt_raw.rank(method=\"first\"), q=4, labels=False, duplicates=\"drop\").astype(\"Int8\")\n",
    "df_enc[\"ok_eng_sen\"] = (df_enc[\"ingles_ok\"] & df_enc[\"senioridade_ok\"]).astype(np.int8)\n",
    "\n",
    "# BLOCO E — SELEÇÃO FINAL E PERSISTÊNCIA\n",
    "keys = [c for c in [\"vaga_id\",\"codigo_candidato\"] if c in df.columns]\n",
    "features = [\n",
    "    \"tech_overlap_count\",\"cand_has_sap\",\"is_sap_vaga\",\"sap_pair\",\n",
    "    \"ingles_ok\",\"espanhol_ok\",\"vaga_ing_rank\",\"cand_ing_rank\",\"vaga_esp_rank\",\"cand_esp_rank\",\n",
    "    \"vaga_sen_rank\",\"cand_sen_rank\",\"senioridade_gap\",\"senioridade_ok\",\n",
    "    \"days_update\",\"situacao_ord\",\"len_cv_bin\",\"ok_eng_sen\",\"len_cv_pt_z\"\n",
    "]\n",
    "\n",
    "df_final = pd.concat([df[keys], df_enc[features]], axis=1)\n",
    "\n",
    "# Downcast para reduzir tamanho\n",
    "for c in df_final.select_dtypes(include=[\"int64\",\"int32\",\"float64\"]):\n",
    "    df_final[c] = pd.to_numeric(df_final[c], downcast=\"integer\")\n",
    "\n",
    "OUT = BASE / \"../data/df_clean.csv\"\n",
    "df_final.to_csv(OUT, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Verificação de candidatos contratados\n",
    "print(\"Verificação da correção:\")\n",
    "print(f\"Total de registros: {len(df_final)}\")\n",
    "print(f\"Distribuição situacao_ord:\\n{df_final['situacao_ord'].value_counts().sort_index()}\")\n",
    "print(f\"Candidatos contratados (situacao_ord=5): {(df_final['situacao_ord']==5).sum()}\")\n",
    "\n",
    "OUT, df_final.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
